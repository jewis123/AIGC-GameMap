{
  "3": {
    "inputs": {
      "seed": 59137742203943,
      "steps": 30,
      "cfg": 7,
      "sampler_name": "dpmpp_2m",
      "scheduler": "karras",
      "denoise": 1,
      "model": [
        "46",
        0
      ],
      "positive": [
        "46",
        1
      ],
      "negative": [
        "46",
        2
      ],
      "latent_image": [
        "46",
        3
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "4": {
    "inputs": {
      "ckpt_name": "SD1.5\\AOM3A3_orangemixs.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "8": {
    "inputs": {
      "samples": [
        "3",
        0
      ],
      "vae": [
        "4",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "15": {
    "inputs": {
      "image": "ddd_mask (1).png"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "17": {
    "inputs": {
      "text": "embedding:EasyNegative_EasyNegative, text,bad_quality,blurry, glitches, artifact, distorted, malformed, dirt, eyeglasses,human,people,person,girl,boy,man,woman.",
      "speak_and_recognation": {
        "__value__": [
          false,
          true
        ]
      },
      "clip": [
        "4",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "21": {
    "inputs": {
      "image": "ddd.png"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "24": {
    "inputs": {
      "brushnet": "random_sd1-5\\diffusion_pytorch_model-001.safetensors",
      "dtype": "float16"
    },
    "class_type": "BrushNetLoader",
    "_meta": {
      "title": "BrushNet Loader"
    }
  },
  "31": {
    "inputs": {
      "size": 1024,
      "interpolation_mode": "bicubic",
      "image": [
        "21",
        0
      ]
    },
    "class_type": "JWImageResizeByLongerSide",
    "_meta": {
      "title": "Image Resize by Longer Side"
    }
  },
  "32": {
    "inputs": {
      "size": 1024,
      "interpolation_mode": "bicubic",
      "image": [
        "15",
        0
      ]
    },
    "class_type": "JWImageResizeByLongerSide",
    "_meta": {
      "title": "Image Resize by Longer Side"
    }
  },
  "35": {
    "inputs": {
      "image": [
        "21",
        0
      ]
    },
    "class_type": "easy imageSize",
    "_meta": {
      "title": "ImageSize"
    }
  },
  "37": {
    "inputs": {
      "model_name": "4x-UltraSharp.pth"
    },
    "class_type": "UpscaleModelLoader",
    "_meta": {
      "title": "Load Upscale Model"
    }
  },
  "38": {
    "inputs": {
      "upscale_method": "bilinear",
      "width": [
        "35",
        0
      ],
      "height": [
        "35",
        1
      ],
      "crop": "disabled",
      "image": [
        "39",
        0
      ]
    },
    "class_type": "ImageScale",
    "_meta": {
      "title": "Upscale Image"
    }
  },
  "39": {
    "inputs": {
      "upscale_model": [
        "37",
        0
      ],
      "image": [
        "8",
        0
      ]
    },
    "class_type": "ImageUpscaleWithModel",
    "_meta": {
      "title": "Upscale Image (using Model)"
    }
  },
  "40": {
    "inputs": {
      "text": "house",
      "seed": 665149223992045,
      "speak_and_recognation": {
        "__value__": [
          false,
          true
        ]
      },
      "clip": [
        "4",
        1
      ]
    },
    "class_type": "SixGodPrompts",
    "_meta": {
      "title": "六神clip文本编码(自动翻译)"
    }
  },
  "42": {
    "inputs": {
      "filename_prefix": "ComfyUI",
      "images": [
        "38",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "46": {
    "inputs": {
      "scale": 1,
      "start_at": 0,
      "end_at": 10000,
      "model": [
        "4",
        0
      ],
      "vae": [
        "4",
        2
      ],
      "image": [
        "31",
        0
      ],
      "mask": [
        "48",
        0
      ],
      "brushnet": [
        "24",
        0
      ],
      "positive": [
        "40",
        0
      ],
      "negative": [
        "17",
        0
      ]
    },
    "class_type": "BrushNet",
    "_meta": {
      "title": "BrushNet"
    }
  },
  "48": {
    "inputs": {
      "channel": "red",
      "image": [
        "32",
        0
      ]
    },
    "class_type": "ImageToMask",
    "_meta": {
      "title": "Convert Image to Mask"
    }
  }
}